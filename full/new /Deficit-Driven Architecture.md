# **Статья 2: Deficit-Driven Architecture (DDA): Системно-кибернетический анализ эволюции архитектур ИИ через призму исторических дефицитов и их инструментальных решений**

---

## **Аннотация**

Каждая архитектура ИИ возникает не в вакууме, а как **ответ на конкретный операционный дефицит** предыдущего поколения. Однако текущая парадигма анализа архитектур фокусируется на технических метриках (accuracy, latency, throughput), игнорируя **археологию проблем** — почему именно такое решение было выбрано, какую боль оно лечило, и какую **новую цену** оно создало.

Данная работа предлагает **Deficit-Driven Architecture (DDA)** — метаархитектурную рамку для:
1. Классификации архитектур ИИ через **дефицит → инструмент → цена → новый дефицит**
2. Формализации **пространства архитектурных решений** через набор компромиссов
3. Прогнозирования **следующего поколения архитектур** через анализ текущих дефицитов
4. Проектирования систем, которые **явно управляют ценой** каждого архитектурного выбора

**Ключевые слова:** архитектура ИИ, дефицит-ориентированное проектирование, эволюция парадигм, цена решений, Goodhart's Law, architectural debt, teleological design.

---

## **Часть I: Центральный тезис и мотивация**

### **1. Проблема: архитектуры без археологии**

**Типичная презентация новой архитектуры:**
> "Мы предлагаем X — новый механизм внимания с O(n log n) вместо O(n²). На бенчмарке Y мы получили +3% accuracy при 2x скорости."

**Что скрыто:**
- Какую **конкретную боль** это решает? (не абстрактная "сложность", а реальная операционная проблема)
- Какие **альтернативы** рассматривались?
- Какую **новую цену** создаёт это решение? (не только техническую, но и эпистемологическую, операционную, социальную)
- В каких **условиях** это решение перестаёт работать? (boundaries, counterworlds)
- Почему **именно сейчас** это стало возможным/необходимым?

### **2. Центральный тезис DDA**

> **Архитектура ИИ — это не технический артефакт, а звено в цепи компромиссов.**

Каждое архитектурное решение:
1. **Лечит** конкретный дефицит предыдущего поколения
2. **Платит** новую цену (техническую, эпистемологическую, операционную)
3. **Создаёт** новый дефицит для следующего поколения

**Формула эволюции:**

$$
\text{Arch}_{n+1} = f(\text{Deficit}(\text{Arch}_n), \text{Constraints}(\text{Context}_n), \text{Enablers}(\text{Tech}_n))
$$

Где:
- $\text{Deficit}(\text{Arch}_n)$ — набор дефицитов текущей архитектуры
- $\text{Constraints}(\text{Context}_n)$ — ограничения среды (экономические, регуляторные, социальные)
- $\text{Enablers}(\text{Tech}_n)$ — доступные технологические enablers (железо, данные, алгоритмы)

### **3. Почему это важно**

**Для исследователей:**
- Понимание **почему** позволяет предсказать **что дальше**
- Избежать **локальной оптимизации** (решать симптомы вместо корня)
- Проектировать архитектуры **с осознанием цены**

**Для инженеров:**
- Выбирать архитектуру, исходя из **конкретного дефицита** системы
- Избегать **cargo cult** (применение решения без понимания проблемы)
- Управлять **архитектурным долгом** (цена, которую мы платим позже)

**Для области в целом:**
- Избежать **циклов повторения** (решение старых проблем под новым названием)
- Создать **язык обсуждения** архитектур через дефициты, а не только через метрики

---

## **Часть II: Пространство дефицитов**

### **4. Таксономия дефицитов в ИИ-системах**

Дефициты можно классифицировать по 5 измерениям:

#### **4.1. Вычислительные дефициты**

| Дефицит | Описание | Типичные проявления |
|---------|----------|---------------------|
| **Латентность** | Время отклика системы | Inference слишком медленный для real-time |
| **Пропускная способность** | Количество запросов в единицу времени | Не можем обслужить нагрузку |
| **Масштабируемость** | Способность обрабатывать рост данных/параметров | Квадратичная сложность убивает на больших входах |
| **Стоимость compute** | Цена обучения/инференса | Обучение стоит $100M+, недоступно малым игрокам |
| **Энергопотребление** | Экологический и экономический след | Inference требует дата-центр |

#### **4.2. Данные и эпистемологические дефициты**

| Дефицит | Описание | Типичные проявления |
|---------|----------|---------------------|
| **Data hunger** | Экспоненциальный рост потребности в данных | Нужно 100x больше данных для следующего улучшения |
| **Качество данных** | Шум, смещения, неполнота | Модель воспроизводит bias из данных |
| **Аннотация** | Стоимость разметки | Нужны тысячи часов ручной работы |
| **Редкие события** | Long tail distribution | Модель плоха на редких, но важных случаях |
| **Синтетические данные** | Model collapse при обучении на ИИ-генерированном | Вырождение через поколения |
| **Galлюцинации** | Генерация правдоподобной лжи | Невозможно использовать в критичных доменах |
| **Provenance** | Невозможность проследить источник знания | Откуда взялось это утверждение? |

#### **4.3. Архитектурные и структурные дефициты**

| Дефицит | Описание | Типичные проявления |
|---------|----------|---------------------|
| **Жёсткость** | Невозможность изменить систему без переобучения | Нужно добавить один навык → переобучить всю модель |
| **Модульность** | Отсутствие разделения на компоненты | Нельзя заменить часть без поломки целого |
| **Иерархичность** | Flat architecture без уровней абстракции | Все связи равноправны, нет приоритета |
| **Специализация** | Одна модель для всего vs. композиция экспертов | Inefficient use of capacity |
| **Контекстное окно** | Ограничение длины входа | Нельзя обработать длинные документы/историю |

#### **4.4. Операционные и инженерные дефициты**

| Дефицит | Описание | Типичные проявления |
|---------|----------|---------------------|
| **Интерпретируемость** | Black box | Почему модель приняла это решение? |
| **Верифицируемость** | Невозможность доказать свойства | Нельзя гарантировать безопасность |
| **Отладка** | Сложность найти и исправить ошибку | "Почему модель сломалась на этом примере?" |
| **Версионирование** | Нет контроля версий знаний модели | Откатить на старую версию — потерять всё |
| **A/B тестирование** | Невозможность изолированно протестировать изменение | Любое изменение влияет на всё |
| **Мониторинг** | Нет метрик деградации в проде | Модель тихо деградирует со временем |

#### **4.5. Социальные и регуляторные дефициты**

| Дефицит | Описание | Типичные проявления |
|---------|----------|---------------------|
| **Доверие** | Невозможность доверять выходу системы | Нужна постоянная ручная проверка |
| **Подотчётность** | Нет ответственного за решение | "Это сделал ИИ" — не аргумент в суде |
| **Fairness** | Дискриминация по защищённым признакам | Модель отказывает меньшинствам |
| **Privacy** | Утечка приватных данных из модели | Training data extraction attacks |
| **Выравнивание** | Misalignment с человеческими ценностями | Модель оптимизирует не то, что нужно |
| **Регуляторика** | Невозможность доказать соответствие нормам | GDPR, medical regulations, safety standards |

---

## **Часть III: Археология архитектур**

### **5. Исторический анализ: дефицит → инструмент → цена**

Проанализируем ключевые архитектурные переходы через призму DDA.

---

#### **5.1. RNN → Transformer (2017)**

**Дефицит RNN:**
- **Вычислительный**: Последовательная обработка (нельзя распараллелить)
- **Архитектурный**: Vanishing gradients на длинных последовательностях
- **Операционный**: Long-range dependencies плохо схватываются

**Решение (Transformer):**
- **Инструмент**: Self-attention механизм
- **Механизм действия**: Каждый токен смотрит на все остальные напрямую (O(n²) связей)
- **Enabler**: GPU с большой памятью стали доступны

**Цена (новые дефициты):**
- **Вычислительная**: O(n²) память и compute по длине последовательности
- **Эпистемологическая**: "Внимание ко всему" → нет приоритизации
- **Архитектурная**: Квадратичный рост делает длинные контексты невозможными

**Следующее поколение решений:**
- Sparse Attention (Longformer, BigBird)
- Linear Attention (Performers, RWKV)
- Recurrent alternatives (Mamba, State Space Models)

---

#### **5.2. Dense Models → Mixture of Experts (2017-2024)**

**Дефицит Dense Models:**
- **Вычислительный**: Используем все параметры для каждого инференса (inefficient)
- **Архитектурный**: Одна модель "знает всё" → interference между доменами
- **Экономический**: Scaling Laws требуют экспоненциального роста параметров

**Решение (MoE):**
- **Инструмент**: Routing mechanism выбирает подмножество экспертов
- **Механизм действия**: Conditional computation (активируем 10% параметров)
- **Enabler**: Достаточно данных, чтобы обучить множество экспертов

**Цена:**
- **Архитектурная**: Routing становится узким местом (как научить router?)
- **Операционная**: Load balancing (эксперты используются неравномерно)
- **Эпистемологическая**: Expert collapse (все запросы идут к одному эксперту)
- **Инфраструктурная**: Сложность деплоя (нужно держать всех экспертов в памяти)

**Текущие дефициты MoE (открытые проблемы):**
- Как обучить router без supervision?
- Как избежать collapse в обучении?
- Как динамически добавлять/удалять экспертов?
- Как сделать экспертов интерпретируемыми? (что знает каждый?)

---

#### **5.3. Autoregressive Generation → Diffusion Models (2020)**

**Дефицит Autoregressive (GPT-like):**
- **Вычислительный**: Последовательная генерация (медленно для изображений/видео)
- **Качественный**: Exposure bias (обучение на ground truth, генерация на своих выходах)
- **Архитектурный**: Сложно контролировать глобальную структуру (нет "видения с конца")

**Решение (Diffusion):**
- **Инструмент**: Iterative refinement (denoising process)
- **Механизм действия**: Начинаем с шума, постепенно улучшаем
- **Enabler**: Score matching, classifier-free guidance

**Цена:**
- **Вычислительная**: Нужно много шагов инференса (50-1000 iterations)
- **Архитектурная**: Нет явного представления структуры (implicit)
- **Операционная**: Сложность контроля (как гарантировать свойства выхода?)

**Текущие дефициты Diffusion:**
- Как ускорить (меньше шагов)?
- Как добавить структурный контроль (композициональность)?
- Как работать с дискретными данными (текст)?

---

#### **5.4. Single-Task Models → Foundation Models (2020-2024)**

**Дефицит Single-Task:**
- **Экономический**: Обучать отдельную модель для каждой задачи дорого
- **Эпистемологический**: Каждая модель "забывает" общие знания, переучивается с нуля
- **Операционный**: Нужно поддерживать десятки моделей

**Решение (Foundation Models):**
- **Инструмент**: Одна большая модель + fine-tuning / prompting
- **Механизм действия**: Transfer learning в экстремальной форме
- **Enabler**: Scaling Laws показали, что размер даёт emergent capabilities

**Цена:**
- **Экономическая**: Обучение стоит $100M+, доступно единицам
- **Социальная**: Централизация власти (кто контролирует модель)
- **Эпистемологическая**: Галлюцинации, bias, alignment problems
- **Операционная**: Невозможность обновить знания без переобучения
- **Регуляторная**: Как регулировать "модель общего назначения"?

**Текущие дефициты Foundation Models:**
- Как обновлять знания без retraining?
- Как гарантировать безопасность?
- Как сделать доступными малым игрокам?
- Как избежать катастрофического забывания при fine-tuning?

---

## **Часть IV: Формализация пространства решений**

### **6. Архитектурные компромиссы как многомерное пространство**

Каждая архитектура — это точка в пространстве компромиссов.

**Оси компромиссов:**

| Ось | Полюс A | Полюс B | Trade-off |
|-----|---------|---------|-----------|
| **Compute** | Эффективность | Мощность | Меньше параметров vs больше capability |
| **Memory** | Компактность | Экспрессивность | Сжатие vs богатство представления |
| **Latency** | Скорость | Качество | Быстрый ответ vs точный ответ |
| **Data** | Sample efficiency | Saturation performance | Мало данных vs потолок качества |
| **Generality** | Специализация | Универсальность | Лучше в узкой задаче vs хуже во всём |
| **Interpretability** | Black box | White box | Производительность vs объяснимость |
| **Robustness** | Brittleness | Stability | Адаптивность vs предсказуемость |
| **Modularity** | Monolith | Composition | Простота vs гибкость |

**Невозможные комбинации (architectural impossibility theorems):**

> **Теорема 1 (Compute-Quality Trade-off):**
> При фиксированном бюджете вычислений, невозможно одновременно максимизировать качество и минимизировать latency для задач, требующих глубокого рассуждения.

> **Теорема 2 (Interpretability-Performance Trade-off):**
> Для большинства задач, полная интерпретируемость (white-box) приводит к потере производительности по сравнению с end-to-end обучением (black-box).

> **Теорема 3 (Generality-Efficiency Trade-off):**
> Модель общего назначения неизбежно менее эффективна по compute/memory, чем специализированная модель для конкретного домена.

---

## **Часть V: Deficit-Driven Design Process**

### **7. Методология проектирования архитектур через дефициты**

**Процесс состоит из 7 этапов:**

---

#### **Этап 1: Deficit Mapping (Картирование дефицитов)**

**Цель:** Понять, какие именно дефициты мы лечим.

**Инструменты:**
- **Deficit Ledger**: Реестр операционных болей системы
- **Root Cause Analysis**: 5 WHY для каждого дефицита
- **Prioritization Matrix**: Дефициты × (Impact, Frequency, Cost of Failure)

**Вопросы:**
- Что конкретно ломается в текущей системе?
- Как часто это происходит?
- Какова цена этой поломки?
- Это симптом или корневая причина?

**Выход:** Приоритизированный список дефицитов с root causes.

---

#### **Этап 2: Alternative Scan (Поиск альтернатив)**

**Цель:** Найти все возможные способы решить дефицит.

**Инструменты:**
- **Technology Radar**: Что существует в смежных областях?
- **Противоположности**: Что будет, если сделать наоборот?
- **Counterworld Analysis**: В каких условиях популярное решение ломается?

**Вопросы:**
- Как эту проблему решали в других доменах?
- Какие радикально иные подходы существуют?
- Почему они не используются сейчас? (Что изменилось?)

**Выход:** Список из 5-10 альтернативных решений с механизмами действия.

---

#### **Этап 3: Price Discovery (Оценка цены)**

**Цель:** Явно определить, что мы теряем, выбирая каждое решение.

**Инструменты:**
- **Price Matrix**: Решение × (Tech Cost, Operational Cost, Epistemic Cost, Social Cost)
- **Second-Order Effects**: Какие новые проблемы создаёт решение?
- **Goodhart Analysis**: Как решение будет gaming'иться?

**Вопросы:**
- Какую новую сложность мы добавляем?
- Какие новые failure modes появляются?
- Какие stakeholders проигрывают от этого решения?
- Какие метрики мы ломаем, оптимизируя новую?

**Выход:** Для каждого решения — явный список цен (краткосрочных и долгосрочных).

---

#### **Этап 4: Boundary Definition (Определение границ)**

**Цель:** Понять, где решение работает, а где ломается.

**Инструменты:**
- **Applicability Map**: Условия × (Работает, Не работает, Неизвестно)
- **Counterworld Generator**: Создание сценариев поломки
- **Stress Testing**: Экстремальные условия

**Вопросы:**
- При каких условиях решение перестаёт работать?
- Какие допущения критичны?
- Что происходит при их нарушении?
- Есть ли фазовые переходы (скачки поведения)?

**Выход:** Явная спецификация границ применимости.

---

#### **Этап 5: Constraint Negotiation (Переговоры об ограничениях)**

**Цель:** Согласовать, какую цену мы готовы платить.

**Инструменты:**
- **Stakeholder Map**: Кто выигрывает/проигрывает от решения
- **Trade-off Negotiation**: Явное обсуждение компромиссов
- **Red Lines**: Что абсолютно неприемлемо (via negativa)

**Вопросы:**
- Кто принимает решение о компромиссах?
- Какие цены неприемлемы ни при каких условиях?
- Как мы будем измерять, что цена растёт?
- Когда мы откажемся от решения?

**Выход:** Согласованная матрица приемлемых компромиссов + red lines.

---

#### **Этап 6: Implementation with Observability (Реализация с наблюдаемостью)**

**Цель:** Построить систему так, чтобы видеть цену в реальном времени.

**Инструменты:**
- **Price Metrics**: Метрики для каждого типа цены
- **Deficit Dashboard**: Мониторинг того, как решение влияет на дефициты
- **Degradation Alerts**: Автоматические алерты при росте цены

**Обязательные метрики:**
- Решается ли исходный дефицит? (Impact metrics)
- Какую новую цену мы платим? (Cost metrics)
- Появились ли новые дефициты? (Second-order metrics)
- Работаем ли мы внутри boundaries? (Applicability metrics)

**Выход:** Система + dashboard наблюдаемости.

---

#### **Этап 7: Evolution Protocol (Протокол эволюции)**

**Цель:** Подготовиться к следующему поколению.

**Инструменты:**
- **Deficit Ledger v2**: Что стало новыми болями?
- **Price Trending**: Как цена меняется со временем?
- **Trigger Conditions**: При каких условиях переходим к новой архитектуре?

**Вопросы:**
- Какие новые дефициты создало наше решение?
- Какие из них становятся критичными?
- Что изменилось в контексте (enablers, constraints)?
- Когда переход к новой архитектуре оправдан?

**Выход:** План миграции на следующее поколение.

---

## **Часть VI: Прогнозирование следующего поколения**

### **8. Текущие дефициты → Архитектуры 2025-2030**

Проанализируем текущие (2024) критичные дефициты и спрогнозируем направления решений.

---

#### **Дефицит 1: Data Wall + Model Collapse**

**Текущее состояние:**
- Качественные данные заканчиваются к 2026-2028
- Синтетические данные ведут к вырождению через поколения
- Юридические барьеры закрывают доступ к данным

**Возможные решения:**

**А) Active Learning Architectures**
- **Механизм**: Модель сама запрашивает аннотацию для максимально информативных примеров
- **Цена**: Нужна инфраструктура для human-in-the-loop
- **Enabler**: Дешевизна краудсорсинга + методы uncertainty estimation

**Б) Structure-First Learning (HNA из статьи 1)**
- **Механизм**: Обучение на структурных паттернах, а не на сырых данных
- **Цена**: Нужно формализовать паттерны, требуется экспертиза
- **Enabler**: Достаточно хорошие LLM для извлечения структуры из текста

**В) Self-Supervised Structure Discovery**
- **Механизм**: Модель учится находить инварианты и паттерны без разметки
- **Цена**: Computationally expensive, может находить ложные паттерны
- **Enabler**: Методы из physics (conservation laws, symmetries)

---

#### **Дефицит 2: Галлюцинации + Отсутствие Provenance**

**Текущее состояние:**
- LLM генерируют правдоподобную ложь
- Невозможно проследить источник утверждения
- Критические домены (медицина, право) не могут использовать

**Возможные решения:**

**А) Evidence-Grounded Generation (из Aegis)**
- **Механизм**: Каждое утверждение привязано к источнику + validity score
- **Цена**: Slower inference, нужна база источников
- **Enabler**: RAG + citation models

**Б) Neuro-Symbolic Hybrid**
- **Механизм**: Нейросеть для понимания, символьная система для вывода
- **Цена**: Сложность интеграции, потеря гибкости
- **Enabler**: Прогресс в differentiable reasoning

**В) Uncertainty-Aware Architectures**
- **Механизм**: Модель явно выдаёт uncertainty, блокирует низкоуверенные ответы
- **Цена**: Может слишком часто говорить "не знаю"
- **Enabler**: Bayesian deep learning, ensemble methods

---

#### **Дефицит 3: Compute Wall + Centralization**

**Текущее состояние:**
- Обучение frontier models стоит $100M+
- Только 3-5 компаний могут себе позволить
- Централизация власти и контроля

**Возможные решения:**

**А) Decentralized Training**
- **Механизм**: Distributed training across many small nodes (blockchain-style)
- **Цена**: Communication overhead, coordination complexity
- **Enabler**: Better compression algorithms, gossip protocols

**Б) Distillation-First Paradigm**
- **Механизм**: Один большой teacher → много маленьких specialized students
- **Цена**: Потеря capabilities при дистилляции
- **Enabler**: Better distillation techniques (hint learning, dark knowledge)

**В) Sparse Mixture of Small Experts**
- **Механизм**: Композиция из множества дешёвых моделей вместо одной дорогой
- **Цена**: Routing complexity, coordination overhead
- **Enabler**: Прогресс в meta-learning, task decomposition

---

#### **Дефицит 4: Context Window Limitations**

**Текущее состояние:**
- Transformer O(n²) ограничивает контекст до ~100K токенов
- Многие задачи требуют миллионы токенов контекста
- Длинный контекст → astronomical compute

**Возможные решения:**

**А) Hierarchical Memory Architectures**
- **Механизм**: Разные слои памяти (short-term, long-term, compressed)
- **Цена**: Сложность управления памятью, что хранить/забывать
- **Enabler**: State Space Models, Memory Networks

**Б) Retrieval-Augmented Everything**
- **Механизм**: Не держим всё в контексте, динамически достаём нужное
- **Цена**: Latency, зависимость от качества retrieval
- **Enabler**: Better embeddings, fast approximate search

**В) Compression-Native Architectures**
- **Механизм**: Учимся сжимать информацию с минимальной потерей
- **Цена**: Какую информацию теряем при сжатии?
- **Enabler**: Information theory, rate-distortion trade-offs

---

## **Часть VII: Метаархитектурные паттерны**

### **9. Повторяющиеся паттерны решений**

Анализируя историю, можно выделить **метапаттерны** — способы решения дефицитов, которые повторяются.

---

#### **Метапаттерн 1: От Монолита к Модулям**

**Примеры:**
- RNN → Transformer (attention modules)
- Dense → MoE (expert modules)
- End-to-end → RAG (retrieval module)

**Паттерн:**
Когда монолитная система становится слишком сложной/дорогой, её разбивают на модули с явными интерфейсами.

**Цена:**
- Нужно проектировать интерфейсы
- Проблема композиции (как модули взаимодействуют?)
- Overhead координации

---

#### **Метапаттерн 2: От Плотного к Разреженному (Sparsity)**

**Примеры:**
- Dense attention → Sparse attention
- Dense models → MoE
- Full fine-tuning → LoRA/Adapters

**Паттерн:**
Когда compute становится узким местом, переходим к conditional computation — активируем только нужное.

**Цена:**
- Как определить "нужное"?
- Как обучить routing?
- Как избежать collapse (всё идёт к одному модулю)?

---

#### **Метапаттерн 3: От Универсального к Специализированному (Specialization)**

**Примеры:**
- General models → Domain-specific fine-tuning
- Single model → Mixture of Experts
- One-size-fits-all → Personalization

**Паттерн:**
Когда общая модель неэффективна, создаём специализированные варианты для подзадач.

**Цена:**
- Нужно определить границы доменов
- Проблема координации между специалистами
- Fragmentation (поддержка множества моделей)

---

#### **Метапаттерн 4: От Неявного к Явному (Explicit Structure)**

**Примеры:**
- Word embeddings → Knowledge graphs
- End-to-end → Neuro-symbolic
- Implicit memory → External memory modules

**Паттерн:**
Когда нужна интерпретируемость или гарантии, извлекаем структуру из implicit representations.

**Цена:**
- Потеря гибкости (structure может быть неправильной)
- Сложность extraction
- Кто определяет правильную структуру?

---

#### **Метапаттерн 5: От Статики к Динамике (Adaptivity)**

**Примеры:**
- Fixed architecture → NAS (Neural Architecture Search)
- Static routing → Learned routing
- Fixed context → Dynamic retrieval

**Паттерн:**
Когда разные задачи требуют разных архитектур, делаем архитектуру адаптивной.

**Цена:**
- Meta-learning complexity
- Как обучать динамическую систему?
- Stability vs. plasticity dilemma

---

## **Часть VIII: Deficit-Driven Research Agenda**

### **10. Открытые проблемы и направления исследований**

На основе анализа дефицитов, сформулируем исследовательскую повестку.

---

#### **Направление 1: Архитектуры с гарантиями (Verifiable AI)**

**Мотивация:** Текущие системы — black box. Критические домены требуют гарантий.

**Ключевые вопросы:**
- Как построить архитектуру, где можно доказать свойства выхода?
- Как совместить neural flexibility с symbolic guarantees?
- Как сделать training provably robust?

**Возможные подходы:**
- Certified robustness через convex relaxations
- Formal verification для нейросетей
- Compositional guarantees (доказываем части, композируем)

---

#### **Направление 2: Self-Correcting Architectures**

**Мотивация:** Модели деградируют со временем, нужна автоматическая коррекция.

**Ключевые вопросы:**
- Как модель может обнаружить свою ошибку?
- Как автоматически собрать данные для исправления?
- Как избежать катастрофического забывания при обновлении?

**Возможные подходы:**
- Uncertainty estimation + active correction
- Continual learning без переобучения
- Meta-learning for self-repair

---

#### **Направление 3: Compositional AI (LEGO для моделей)**

**Мотивация:** Нужна возможность композировать модели как функции.

**Ключевые вопросы:**
- Какие интерфейсы нужны для композиции?
- Как гарантировать свойства при композиции?
- Как избежать semantic drift при цепочке моделей?

**Возможные подходы:**
- Functional programming для моделей
- Type systems для neural modules
- Contracts and invariants для композиции

---

#### **Направление 4: Deficit-Aware Learning**

**Мотивация:** Система должна знать, чего она не знает.

**Ключевые вопросы:**
- Как модель может оценить boundaries своих знаний?
- Как автоматически обнаружить дефициты в обучении?
- Как приоритизировать сбор данных для устранения дефицитов?

**Возможные подходы:**
- Active learning with uncertainty
- Coverage metrics для пространства задач
- Deficit-driven curriculum learning

---

## **Часть IX: Инварианты DDA**

### **11. Правила, переживающие смену архитектур**

1. **Дефицит первичен.** Архитектура без понимания дефицита — cargo cult.

2. **Цена неизбежна.** Каждое решение создаёт новую проблему. Вопрос не "есть ли цена", а "приемлема ли она".

3. **Границы обязательны.** Решение без границ применимости — ложная универсализация.

4. **Альтернативы необходимы.** Единственное решение — признак недостаточного анализа.

5. **Противоположность поучительна.** "Что если наоборот?" открывает скрытые допущения.

6. **Enablers определяют возможное.** Решение может быть правильным, но преждевременным.

7. **Компромиссы явны.** Что мы выбрали и от чего отказались должно быть документировано.

8. **Наблюдаемость обязательна.** Цену нужно измерять в реальном времени.

9. **Эволюция неизбежна.** Каждая архитектура временна. Вопрос — когда переходить.

10. **Контекст критичен.** Лучшая архитектура зависит от ограничений среды.

---

## **Часть X: Заключение**

### **12. Резюме**

Deficit-Driven Architecture (DDA) — это метаархитектурная рамка, которая:

1. **Классифицирует архитектуры** через дефицит → решение → цена → новый дефицит
2. **Формализует пространство компромиссов** через невозможные комбинации
3. **Предлагает процесс проектирования** через 7 этапов (от deficit mapping до evolution protocol)
4. **Прогнозирует будущее** через анализ текущих дефицитов
5. **Выделяет метапаттерны** решений, повторяющиеся в истории

**Центральный тезис:**

> **Архитектура — это не технический артефакт, а звено в цепи компромиссов. Понимание археологии проблем важнее метрик.**

---
